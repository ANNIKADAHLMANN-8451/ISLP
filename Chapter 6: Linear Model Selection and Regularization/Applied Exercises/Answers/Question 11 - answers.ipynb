{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f53c375-600c-4724-8d69-7ab18d0b3bb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fede74b-84ac-4f1a-a96b-2b5f507550e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We will now try to predict per capita crime rate in the `Boston` data\n",
    "set. Note, this notebook was modified from the original repo as the `normalize` parameter in some of the model instance functions has since been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61cb1f00-2596-48ad-9fb5-9c71f09b4102",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6e64bc6-e926-4e2f-92c1-58bdff48d89f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant statistical packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a9eb93a-e62c-4021-9291-f321559d16af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant data visualisation packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f56d5e9b-1f04-46a4-a171-65216853891b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import custom packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score as r2, mean_squared_error\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from mlxtend.plotting import plot_linear_regression as PLS\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd6e4ef9-9488-465a-9b27-6d28f149767d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "url = \"abfss://training@sa8451learningdev.dfs.core.windows.net/interpretable_machine_learning/eml_data/Boston.csv\"\n",
    "Boston = spark.read.option(\"header\", \"true\").csv(url).toPandas().astype(float)\n",
    "Boston.set_index(\"SlNo\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed16c432-bfb0-4282-93cf-0d04883a8975",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5223270-792f-4007-b89e-2fa4674c9208",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Boston = pd.get_dummies(Boston, columns =['chas'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f0a423-56fc-4b30-95d3-d3be846d5a76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = Boston.drop(columns='crim')\n",
    "y = Boston['crim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b3e1fb6-9b4b-4c4d-9ca6-ea1f96d4d73a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**a. Try out some of the regression methods explored in this chapter,\n",
    "such as best subset selection, the lasso, ridge regression, and\n",
    "PCR. Present and discuss results for the approaches that you\n",
    "consider.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbeaaee9-21e6-4ea8-b83b-780c27764f5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19dc66c2-7d36-4ad4-bb07-d8c5c918bbd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4368a143-5ceb-4ce6-aab5-d1ced98ab7a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "lambdas = (np.logspace(10, -2, num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74b1f76-fdaf-4f30-9e6b-e9938f36e681",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "coefs = []\n",
    "\n",
    "for k in lambdas:\n",
    "    lassolm = lasso.set_params(alpha = k).fit(X, y)\n",
    "    coefs.append(lassolm.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd432122-fac0-4a1e-9d25-753eae64aee2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plt.figure(figsize = (25, 10))\n",
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda', fontsize = 20)\n",
    "plt.ylabel('coefficients', fontsize = 20)\n",
    "plt.title('coefficients as function of lambdas', fontsize = 30)\n",
    "plt.legend(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900b5189-e957-4d35-86b2-97b4b83e9fb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*This graph suggests that coefficients are likely to be larger near $\\lambda$=0 (at $\\lambda$=0, it will exactly be like least squares regression. So, I will need a $\\lambda$-value slightly higher than that to ensure sufficient reduction in variance. What is interesting however, is that different coefficients reduce to 0 with increasing $\\lambda$. This suggests lasso can perform variable selection in addition to variance reduction.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08fc85b0-0f37-4a1d-8f38-dacca7d75f87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# splitting the Boston dataset into training and test data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00227111-e64e-4cdd-bb9e-1ee996e1d8fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0\n",
    "lasso0 = Lasso(alpha = 0).fit(X_train, y_train)\n",
    "lassopred0 = lasso0.predict(scale(X_test))\n",
    "lassocoefs0 = pd.Series(lasso0.coef_, index = X.columns)\n",
    "lassointercept0 = pd.Series(lasso0.intercept_, index = ['Intercept'])\n",
    "lassotable0 = pd.DataFrame(pd.concat([lassointercept0, lassocoefs0]))\n",
    "lassotable0.columns = ['Coefficients']\n",
    "lassotable0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "019b4ff7-3527-42e0-81b4-543d30625164",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassoerror0 = mean_squared_error(y_test, lassopred0)\n",
    "lassoerror0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3603d709-2534-412e-9d66-d97c3dfec77a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*As explained above, setting $\\lambda$=0 returns the same value of coefficients as that of least squares regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff472550-ddc2-4375-915f-d019210587f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Selecting $\\lambda$ through cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d83c9218-1f00-425e-942b-0cdf54559874",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassocv = LassoCV(alphas = lambdas).fit(X_train, y_train)\n",
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecd2fcf0-7125-4ae1-a8c4-510e3b76b6dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*Therefore, the $\\lambda$ with the smallest cross-validation error is at 0.013219411484660288.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "186c13ad-2979-4b67-be5a-86ad7864520d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0.013219411484660288\n",
    "lasso0013 = Lasso(alpha = lassocv.alpha_).fit(X_train, y_train)\n",
    "lassopred0013 = lasso0013.predict(scale(X_test))\n",
    "lassocoefs0013 = pd.Series(lasso0013.coef_, index = X.columns)\n",
    "lassointercept0013 = pd.Series(lasso0013.intercept_, index = ['Intercept'])\n",
    "lassotable0013 = pd.DataFrame(pd.concat([lassointercept0013, lassocoefs0013]))\n",
    "lassotable0013.columns = ['Coefficients']\n",
    "lassotable0013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dda96893-8b78-483f-a685-5c27ac8829b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassoerror0013 = mean_squared_error(y_test, lassopred0013)\n",
    "lassoerror0013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85644de0-69e5-49b6-be4e-ec509eb18aab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0c79539-d79c-476a-8b4a-d8058d0c128d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b802aca-35e3-467f-9570-cce8cf11eeec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "lambdas = (np.logspace(10, -2, num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14a16167-b13a-4ba5-8d4d-d39251b5c87d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "coefs = []\n",
    "\n",
    "for k in lambdas:\n",
    "    ridgelm = ridge.set_params(alpha = k).fit(X, y)\n",
    "    coefs.append(ridgelm.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7b390d5-f573-47e7-b2a7-641bf297f7b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plt.figure(figsize = (25, 10))\n",
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda', fontsize = 20)\n",
    "plt.ylabel('coefficients', fontsize = 20)\n",
    "plt.title('coefficients as function of lambdas', fontsize = 30)\n",
    "plt.legend(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e38c0ae-5b10-4658-bdd7-85f2fd0acaad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*This graph suggests that coefficients are likely to be larger near $\\lambda$=0 (at $\\lambda$=0, it will exactly be like least squares regression. So, I will need a $\\lambda$-value slightly higher than that to ensure sufficient reduction in variance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5088be0b-df62-4ede-aee0-9bf061559875",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0\n",
    "ridge0 = Ridge(alpha = 0).fit(X_train, y_train)\n",
    "ridgepred0 = ridge0.predict(scale(X_test))\n",
    "ridgecoefs0 = pd.Series(ridge0.coef_, index = X.columns)\n",
    "ridgeintercept0 = pd.Series(ridge0.intercept_, index = ['Intercept'])\n",
    "ridgetable0 = pd.DataFrame(pd.concat([ridgeintercept0, ridgecoefs0]))\n",
    "ridgetable0.columns = ['Coefficients']\n",
    "ridgetable0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76d7024-ea0e-43f8-b69f-1e3f86538860",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridgeerror0 = mean_squared_error(y_test, ridgepred0)\n",
    "ridgeerror0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "059839ff-df34-4701-875d-a149785706e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*As explained above, setting $\\lambda$=0 returns the same value of coefficients as that of least squares regression. What's interesting to note that the coefficients and the MSE through ridge regression is the same as those through lasso\n",
    "regression at $\\lambda$=0.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd45bd03-7365-4dd0-a765-66d1b7d6cce4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Selecting $\\lambda$ through cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14a2a212-ffaa-4d30-a82a-88f592761b56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas = lambdas, scoring = 'neg_mean_squared_error').fit(X_train, y_train)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9eaad7c-2ee5-458a-9521-53d455e8f10e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*Therefore, the $\\lambda$ with the smallest cross-validation error is at 0.07054802310718632.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4815740e-7b4b-469b-8781-1013fed5ca95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0.07054802310718632\n",
    "ridge007 = Ridge(alpha = ridgecv.alpha_).fit(X_train, y_train)\n",
    "ridgepred007 = ridge007.predict(scale(X_test))\n",
    "ridgecoefs007 = pd.Series(ridge007.coef_, index = X.columns)\n",
    "ridgeintercept007 = pd.Series(ridge007.intercept_, index = ['Intercept'])\n",
    "ridgetable007 = pd.DataFrame(pd.concat([ridgeintercept007, ridgecoefs007]))\n",
    "ridgetable007.columns = ['Coefficients']\n",
    "ridgetable007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b4e6347-8e09-4f3f-9a7c-e45f4b11a3d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridgeerror007 = mean_squared_error(y_test, ridgepred007)\n",
    "ridgeerror007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51e0cf38-4f7c-43ed-ad9e-7712638b645a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Principal components regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "764bbedd-ed86-4342-bb4b-9e1ecdca4193",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold as KF, cross_val_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21de627f-ec19-470a-b4ad-ddd85f16ebf4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_scaled = pca.fit_transform(scale(X))\n",
    "pd.DataFrame(pca.components_.T).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "133fa297-90b3-4c27-a645-e505c01c95a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# selecting M, the number of components that give the lowest cross-validation error\n",
    "n = len(X)\n",
    "kf10 = KF(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "lm = LinearRegression()\n",
    "MSEdf= pd.DataFrame()\n",
    "\n",
    "# calculating MSE with only the intercept through cross-validation\n",
    "mse = -1*cross_val_score(lm, np.ones((n,1)), y.ravel(), cv=kf10, scoring='neg_mean_squared_error').mean()    \n",
    "MSEdf = MSEdf.append([round(mse, 9)])\n",
    "\n",
    "# calculating MSE for the 20 components through cross-validation\n",
    "for i in np.arange(1, 21):\n",
    "    mse = -1*cross_val_score(lm, X_scaled[:,:i], y.ravel(), cv=kf10, scoring='neg_mean_squared_error').mean()\n",
    "    MSEdf = MSEdf.append([round(mse, 9)])\n",
    "    \n",
    "MSEdf.reset_index(drop=True, inplace=True)\n",
    "MSEdf.columns = ['MSE']\n",
    "MSEdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c5de73-15f4-4825-abc0-720377cfde78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting MSE for each component\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(MSEdf)\n",
    "plt.title('MSE vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('MSE', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a2f145-fe52-422d-bd16-75c4e1414a60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting explained variance ratio\n",
    "exp_var_ratio = pd.DataFrame(np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100))\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(exp_var_ratio, color='green', linestyle ='-.', marker='o', markersize=10, markerfacecolor='orange')\n",
    "plt.title('explained variance ratio vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('explained variance ratio', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7316639-d946-4e92-ae81-b3dc738289b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*This suggests that I will get the lowest MSE at M=12 and flattens thereafter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0eb16b4-95e7-41cf-8afb-16cbad8d8075",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# performing PCR on train and test data sets\n",
    "pca_train = PCA()\n",
    "X_scaled_train = pca_train.fit_transform(scale(X_train))\n",
    "n = len(X_scaled_train)\n",
    "\n",
    "lmtrain = LinearRegression()\n",
    "\n",
    "kf10train = KF(n_splits=10, shuffle=True, random_state=42)\n",
    "MSEdftrain= pd.DataFrame()\n",
    "\n",
    "# calculating MSE with only the intercept through cross-validation\n",
    "msetrain = -1*cross_val_score(lmtrain, np.ones((n,1)), y_train.ravel(), cv=kf10train, scoring='neg_mean_squared_error').mean()    \n",
    "MSEdftrain = MSEdftrain.append([msetrain])\n",
    "\n",
    "# calculating MSE for the 20 components through cross-validation\n",
    "for i in np.arange(1, 21):\n",
    "    msetrain = -1*cross_val_score(lmtrain, X_scaled_train[:,:i], y_train.ravel(), cv=kf10train, scoring='neg_mean_squared_error').mean()\n",
    "    MSEdftrain = MSEdftrain.append([msetrain])\n",
    "    \n",
    "MSEdftrain.reset_index(drop=True, inplace=True)\n",
    "MSEdftrain.columns = ['MSE']\n",
    "MSEdftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "326f1690-4676-4eb3-97dc-2cbf19304222",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting MSE for each component\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(MSEdftrain)\n",
    "plt.title('MSE vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('MSE', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5d94a5a-eaf4-4844-9fa4-96ab3f247654",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting explained variance ratio\n",
    "exp_var_ratio_scaled = pd.DataFrame(np.cumsum(np.round(pca_train.explained_variance_ratio_, decimals=4)*100))\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(exp_var_ratio_scaled, color='green', linestyle ='-.', marker='o', markersize=10, markerfacecolor='orange')\n",
    "plt.title('explained variance ratio vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('explained variance ratio', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07baa823-688b-4daa-858e-4a1c9f5fd4c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*The two graphs above are quite interesting, The first graph suggests that the least MSE occurs at M=3. But, if we check the explained variance ratio, only  76.82% of the variance is explained by M=3 as comparied to 100% for M=12. So, it seems right that the ideal number of principal components is M=12.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4722222-1b7a-4df3-b27e-f5603b787f7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baa1e350-a29b-4db0-9a9e-efa10ed54af2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pca_test = PCA(n_components=12)\n",
    "X_scaled_test = pca_test.fit_transform(scale(X_test))\n",
    "pcrfit12 = LinearRegression().fit(X_scaled_train, y_train)\n",
    "y_test_pd = pd.DataFrame({'y': y_test})\n",
    "X_scaled_test = np.concatenate((X_scaled_test, y_test_pd), axis=1)\n",
    "pcrpred12 = pcrfit12.predict(X_scaled_test)\n",
    "\n",
    "pcrerror12 = mean_squared_error(y_test, pcrpred12)\n",
    "pcrerror12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec43510e-ba24-42a6-9c07-b81ed06df6df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**b. Propose a model (or set of models) that seem to perform well on\n",
    "this data set, and justify your answer. Make sure that you are\n",
    "evaluating model performance using validation set error, crossvalidation, or some other reasonable alternative, as opposed to\n",
    "using training error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51a5be1a-ff8d-4745-a33a-8935eab70be7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "errordf = pd.DataFrame([lassoerror0013, ridgeerror007, pcrerror12], ['lasso', 'ridge', 'pcr'])\n",
    "errordf.columns = ['error']\n",
    "errordf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e808101f-43f7-4c69-b3b2-fbe292c16946",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Therefore, I will choose the lasso because it generates the least mean squared error on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9624d9d7-aa4b-4bbe-9d03-7aa550ca9bd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**c. Does your chosen model involve all of the features in the data\n",
    "set? Why or why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86b5dd10-13df-4621-81c0-c483cc6fd7cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassotable0013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43661a26-7439-4c02-9836-abedb1810957",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "No, it does not incorporate all features. Therefore, the equation with lasso will be $Y$ = $1.692065$ + $0.001496AGE$ - $0.203664DIS$ + $0.478376RAD$ + $0.000344TAX$ - $0.007527B$ + $0.041371LSTAT$ - $0.556786CHAS(=1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0924f16d-6cba-4b36-8a99-eafe9a16239f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassotable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e49381c-aef6-41be-b0eb-f2380c478bd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This is because rest of the features are approximately equal to 0. Therefore, lasso punishes these features by reducing them to exactly 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e1a3648-4977-488e-a164-ddda11bcb605",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Question 11 - answers",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
