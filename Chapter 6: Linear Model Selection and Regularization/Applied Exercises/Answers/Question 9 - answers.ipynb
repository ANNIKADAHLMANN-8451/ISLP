{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03ca2289-c928-4c22-a4c8-7806b15ef401",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f542f2-f8b4-4266-8eed-31bdc95d453b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this exercise, we will predict the number of applications received\n",
    "using the other variables in the `College` data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b485352-8c5d-40ea-90b8-4194dc802d83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af39faff-aff5-4d53-9da2-71a25e520dc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant statistical packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd786bf1-50c0-4da4-9795-c8697ec213b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant data visualisation packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "781cce93-8915-413c-9fea-4d81f3954275",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import custom packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score as r2, mean_squared_error\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from mlxtend.plotting import plot_linear_regression as PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a80871fa-28e7-44ac-bff0-34e05d38935b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "url = \"abfss://training@sa8451learningdev.dfs.core.windows.net/interpretable_machine_learning/eml_data/College.csv\"\n",
    "College = spark.read.option(\"header\", \"true\").csv(url).toPandas()\n",
    "College.set_index('_c0', inplace=True)\n",
    "\n",
    "str_cols = [\"Private\"]\n",
    "float_cols = [\"S.F.Ratio\"]\n",
    "int_cols = list(set(College.columns)-set(str_cols)-set(float_cols))\n",
    "College[int_cols] = College[int_cols].astype(int)\n",
    "College[str_cols] = College[str_cols].astype(str)\n",
    "College[float_cols] = College[float_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2456fcd1-4f6d-442e-8d39-953d20d59981",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "College.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc54b828-2d5a-407f-b4e4-acdbf9fb6eba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "College.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d3730e-2218-4e4b-8238-a3880f3eb605",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plt.figure(figsize = (25, 10))\n",
    "sns.heatmap(College.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fcf1d2c-654b-4940-881a-a5157d7c978d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*There are no missing values as suggested by the heatmap above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b163fc7b-9ec2-447c-a809-a4169225fecc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "College = pd.get_dummies(College, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55db4ea3-b00f-413d-9d63-a86cb4062002",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "College.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e5319a2-5185-4528-9a9f-e436fe587cb8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**a. Split the data set into a training set and a test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3a938b5-0064-48b7-92c4-8c4f9b741425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e114070-ef21-4ddd-97d8-faba79091e0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = College.drop(columns=['Apps'])\n",
    "y = College['Apps']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8e1bd3e-d2ee-4a4f-8d22-d0e00b877caa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbf73aa5-7076-408e-a748-824d9bafa0e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**b. Fit a linear model using least squares on the training set, and\n",
    "report the test error obtained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19557ab0-b772-4881-a368-0425b38ea104",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lmfit = LinearRegression().fit(X_train, y_train)\n",
    "lmpred = lmfit.predict(X_test)\n",
    "lmcoefs = pd.Series(lmfit.coef_, index = X.columns)\n",
    "lmintercept = pd.Series(lmfit.intercept_, index = ['Intercept'])\n",
    "lmtable = pd.DataFrame(pd.concat([lmintercept, lmcoefs]))\n",
    "lmtable.columns = ['Coefficients']\n",
    "lmtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c411c0dd-ad84-43da-82e2-6c880ce7e74f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lmerror = mean_squared_error(y_test, lmpred)\n",
    "lmerror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d491179f-5e10-4787-9679-be483b380e52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**c. Fit a ridge regression model on the training set, with λ chosen\n",
    "by cross-validation. Report the test error obtained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd14a3e1-86b3-482c-b804-bdd83aa1771c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1ce730-6444-49c1-b697-a87b4248cf23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "lambdas = (np.logspace(10, -2, num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20ec9b3d-bc60-4d43-97ad-081191d31f08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "coefs = []\n",
    "\n",
    "for k in lambdas:\n",
    "    ridgelm = ridge.set_params(alpha = k).fit(X, y)\n",
    "    coefs.append(ridgelm.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3a4a297-81e9-4ed6-8f78-2001fbb17a3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plt.figure(figsize = (25, 10))\n",
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda', fontsize = 20)\n",
    "plt.ylabel('coefficients', fontsize = 20)\n",
    "plt.title('coefficients as function of lambdas', fontsize = 30)\n",
    "plt.legend(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dd8c7f3-5c40-4b29-a98e-5c1381baa5a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*This graph suggests that coefficients are likely to be larger near $\\lambda$=0 (at $\\lambda$=0, it will exactly be like least squares regression. So, I will need a $\\lambda$-value slightly higher than that to ensure sufficient reduction in variance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19cfacaf-c9a3-4474-bd12-52b36183a05d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0\n",
    "ridge0 = Ridge(alpha = 0).fit(X_train, y_train)\n",
    "ridgepred0 = ridge0.predict(X_test)\n",
    "ridgecoefs0 = pd.Series(ridge0.coef_, index = X.columns)\n",
    "ridgeintercept0 = pd.Series(ridge0.intercept_, index = ['Intercept'])\n",
    "ridgetable0 = pd.DataFrame(pd.concat([ridgeintercept0, ridgecoefs0]))\n",
    "ridgetable0.columns = ['Coefficients']\n",
    "ridgetable0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1069371b-8508-4cd8-891b-5d742a598035",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridgeerror0 = mean_squared_error(y_test, ridgepred0)\n",
    "ridgeerror0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5db4f183-6160-48a3-b0f5-5f585143dbb3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*As explained above, setting $\\lambda$=0 returns the same value of coefficients as that of least squares regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab07a228-e77b-41df-b9fc-f7734a790167",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Select the best lambda using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de565b66-29af-42e8-b17b-ef69e034348c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas = lambdas, scoring = 'neg_mean_squared_error').fit(X_train, y_train)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d26837b3-5856-4d77-9271-2b9ad3de1e94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*Therefore, the $\\lambda$ with the smallest cross-validation error is at 0.01.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25df25a9-9ca1-43e3-b333-146e7f528add",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0.01\n",
    "ridge001 = Ridge(alpha = ridgecv.alpha_).fit(X_train, y_train)\n",
    "ridgepred001 = ridge001.predict(X_test)\n",
    "ridgecoefs001 = pd.Series(ridge001.coef_, index = X.columns)\n",
    "ridgeintercept001 = pd.Series(ridge001.intercept_, index = ['Intercept'])\n",
    "ridgetable001 = pd.DataFrame(pd.concat([ridgeintercept001, ridgecoefs001]))\n",
    "ridgetable001.columns = ['Coefficients']\n",
    "ridgetable001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5a5e9d0-c885-4311-a8be-a32686a5af3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridgeerror001 = mean_squared_error(y_test, ridgepred001)\n",
    "ridgeerror001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5403ee8-a8bf-4fdc-bc12-61a57d6871ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Therefore, the MSE through ridge regression for the best value of $\\lambda$ is slightly higher than that of least squares regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0870b863-5212-4cff-9d27-832f8519a49f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**d. Fit a lasso model on the training set, with λ chosen by crossvalidation. Report the test error obtained, along with the number of non-zero coefcient estimates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28c71bf1-84a5-4b61-a311-c9c3b1ac0ab5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e08e5f-3276-470e-80ff-4058bba0d430",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "lambdas = (np.logspace(10, -2, num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cded3968-e0d7-4e17-8999-809ca578af0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "coefs = []\n",
    "\n",
    "for k in lambdas:\n",
    "    lassolm = lasso.set_params(alpha = k).fit(X, y)\n",
    "    coefs.append(lassolm.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25329fb8-ebad-46f6-9921-fb7a21b7e697",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plt.figure(figsize = (25, 10))\n",
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda', fontsize = 20)\n",
    "plt.ylabel('coefficients', fontsize = 20)\n",
    "plt.title('coefficients as function of lambdas', fontsize = 30)\n",
    "plt.legend(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cddf7110-3672-48ee-b66e-6ee4e1849fef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*This graph suggests that coefficients are likely to be larger near $\\lambda$=0 (at $\\lambda$=0, it will exactly be like least squares regression. So, I will need a $\\lambda$-value slightly higher than that to ensure sufficient reduction in variance. What is interesting however, is that different coefficients reduce to 0 with increasing $\\lambda$. This suggests lasso can perform variable selection in addition to variance reduction.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a637e8c-d0c0-4944-9d59-3cf004702783",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0\n",
    "lasso0 = Lasso(alpha = 0).fit(X_train, y_train)\n",
    "lassopred0 = lasso0.predict(X_test)\n",
    "lassocoefs0 = pd.Series(lasso0.coef_, index = X.columns)\n",
    "lassointercept0 = pd.Series(lasso0.intercept_, index = ['Intercept'])\n",
    "lassotable0 = pd.DataFrame(pd.concat([lassointercept0, lassocoefs0]))\n",
    "lassotable0.columns = ['Coefficients']\n",
    "lassotable0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50992145-d014-4118-960f-0042f53a7634",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassoerror0 = mean_squared_error(y_test, lassopred0)\n",
    "lassoerror0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fbf912c-3044-4e7b-94d3-63b43b8da97d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*As explained above, setting $\\lambda$=0 returns the same value of coefficients as that of least squares regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "081a081f-c94a-4e9d-b2a8-fc3f82b0a5a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Selecting $\\lambda$ through cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b288b84-f694-4583-a253-1ff77742db5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassocv = LassoCV(alphas = lambdas).fit(X_train, y_train)\n",
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03c181d6-f931-446f-a9aa-076dd3aee62f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*Therefore, the $\\lambda$ with the smallest cross-validation error is at 0.053366992312063016.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d33e3c3e-0d12-4b4c-8cc7-77b63c6d0dc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lambda = 0.053366992312063016\n",
    "lasso005 = Lasso(alpha = lassocv.alpha_).fit(X_train, y_train)\n",
    "lassopred005 = lasso005.predict(X_test)\n",
    "lassocoefs005 = pd.Series(lasso005.coef_, index = X.columns)\n",
    "lassointercept005 = pd.Series(lasso005.intercept_, index = ['Intercept'])\n",
    "lassotable005 = pd.DataFrame(pd.concat([lassointercept005, lassocoefs005]))\n",
    "lassotable005.columns = ['Coefficients']\n",
    "lassotable005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c2bc1b-40d1-4edf-bb11-2069831a3d2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassoerror005 = mean_squared_error(y_test, lassopred005)\n",
    "lassoerror005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3b337d-84a8-4614-a4cf-ad0473c9c965",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Therefore, the MSE through lasso regression for the best value of $\\lambda$ is slightly higher than that of least squares regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d449321c-d45c-4424-949d-5257569faa36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**e. Fit a PCR model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value\n",
    "of M selected by cross-validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b630cf9a-dd21-40f8-968c-0d2227492c2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold as KF\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e336cafc-dae8-4909-b79f-f335d46da831",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_scaled = pca.fit_transform(scale(X))\n",
    "pd.DataFrame(pca.components_.T).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d8fd5e6-0930-4a42-a766-025dbed27b84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# selecting M, the number of components that give the lowest cross-validation error\n",
    "n = len(X)\n",
    "kf10 = KF(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "lm = LinearRegression()\n",
    "MSEdf= pd.DataFrame()\n",
    "\n",
    "# calculating MSE with only the intercept through cross-validation\n",
    "mse = -1*cross_val_score(lm, np.ones((n,1)), y.ravel(), cv=kf10, scoring='neg_mean_squared_error').mean()    \n",
    "MSEdf = MSEdf.append([round(mse, 9)])\n",
    "\n",
    "# calculating MSE for the 17 components through cross-validation\n",
    "for i in np.arange(1, 18):\n",
    "    mse = -1*cross_val_score(lm, X_scaled[:,:i], y.ravel(), cv=kf10, scoring='neg_mean_squared_error').mean()\n",
    "    MSEdf = MSEdf.append([round(mse, 9)])\n",
    "    \n",
    "MSEdf.reset_index(drop=True, inplace=True)\n",
    "MSEdf.columns = ['MSE']\n",
    "MSEdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "385cd2ab-08e7-4a2a-a8a8-4368b1e118cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting MSE for each component\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(MSEdf)\n",
    "plt.title('MSE vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('MSE', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d2f1f12-ced7-4b3a-96b4-682ccb5b5f1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting explained variance ratio\n",
    "exp_var_ratio = pd.DataFrame(np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100))\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(exp_var_ratio, color='green', linestyle ='-.', marker='o', markersize=10, markerfacecolor='orange')\n",
    "plt.title('explained variance ratio vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('explained variance ratio', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c7193b5-ca9b-4cf7-8a44-e8119e4f61fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*This suggests that I will get the lowest MSE at M=17, which is the same as performing a regular least squares regression! So, I will now perform PCR on the training set and validate the model using the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3168b8a1-d6c9-46ba-b9db-28f3697ec0ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# performing PCR on train and test data sets\n",
    "pca_train = PCA()\n",
    "X_scaled_train = pca_train.fit_transform(scale(X_train))\n",
    "n = len(X_scaled_train)\n",
    "\n",
    "lmtrain = LinearRegression()\n",
    "\n",
    "kf10train = KF(n_splits=10, shuffle=True, random_state=42)\n",
    "MSEdftrain= pd.DataFrame()\n",
    "\n",
    "# calculating MSE with only the intercept through cross-validation\n",
    "msetrain = -1*cross_val_score(lmtrain, np.ones((n,1)), y_train.ravel(), cv=kf10train, scoring='neg_mean_squared_error').mean()    \n",
    "MSEdftrain = MSEdftrain.append([msetrain])\n",
    "\n",
    "# calculating MSE for the 17 components through cross-validation\n",
    "for i in np.arange(1, 18):\n",
    "    msetrain = -1*cross_val_score(lmtrain, X_scaled_train[:,:i], y_train.ravel(), cv=kf10train, scoring='neg_mean_squared_error').mean()\n",
    "    MSEdftrain = MSEdftrain.append([msetrain])\n",
    "    \n",
    "MSEdftrain.reset_index(drop=True, inplace=True)\n",
    "MSEdftrain.columns = ['MSE']\n",
    "MSEdftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f3d87e7-6d4f-4aef-a946-47bf985c6da0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting MSE for each component\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(MSEdftrain)\n",
    "plt.title('MSE vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('MSE', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d9da7c6-da69-4774-9872-006aff333fe6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting explained variance ratio\n",
    "exp_var_ratio_scaled = pd.DataFrame(np.cumsum(np.round(pca_train.explained_variance_ratio_, decimals=4)*100))\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(exp_var_ratio_scaled, color='green', linestyle ='-.', marker='o', markersize=10, markerfacecolor='orange')\n",
    "plt.title('explained variance ratio vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('explained variance ratio', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52526424-f5c3-4bd5-a4bf-e92189f837d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*While the MSEs themselves are somewhat reduced due to scaling, the results still suggest that I will get the best test MSE at M=17.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "405ba90e-12e6-478c-9acc-8135eaa7a7b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_scaled_test = pca.fit_transform(scale(X_test))\n",
    "pcrfit17 = LinearRegression().fit(X_scaled_train, y_train)\n",
    "pcrpred17 = pcrfit17.predict(X_scaled_test)\n",
    "\n",
    "pcrerror17 = mean_squared_error(y_test, pcrpred17)\n",
    "pcrerror17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72f47626-52d0-48a9-95bf-e561380730c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "So far, PCR has produced the largest MSE amongst all models used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dff814a-8674-42fd-8d5d-176378581276",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**f. Fit a PLS model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value\n",
    "of M selected by cross-validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e4921e3-63a1-49e9-8d99-c4c4f1ec9067",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression as PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46060b20-c832-4653-8740-75c5e51f4c96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# performing PLS on train and test data sets\n",
    "n = len(X_train)\n",
    "kf10train = KF(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "MSEdftrain= pd.DataFrame()\n",
    "\n",
    "# calculating MSE for the 17 components through cross-validation\n",
    "for k in np.arange(1, 18):\n",
    "    plstrain = PLS(n_components=k)\n",
    "    msetrain = -1*cross_val_score(plstrain, scale(X_train), y_train.ravel(), cv=kf10train, scoring='neg_mean_squared_error').mean()\n",
    "    MSEdftrain = MSEdftrain.append([msetrain])\n",
    "    \n",
    "MSEdftrain.reset_index(drop=True, inplace=True)\n",
    "MSEdftrain.columns = ['MSE']\n",
    "MSEdftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fbeee89-2702-4c09-bfc4-e75f24c84636",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting MSE for each component\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(MSEdftrain)\n",
    "plt.title('MSE vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('MSE', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69702345-5c38-4ba3-9941-31dec5b54cbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explained_variance_ratio_test = np.var(scale(X_train), axis=0) / np.sum(np.var(scale(X_train), axis=0)) # PLS does not have any method to automatically calculate explained variance ratio\n",
    "EVR17 = pd.DataFrame(np.cumsum(np.round(explained_variance_ratio_test, decimals=4)*100), columns=['Explained Variance Ratio'])\n",
    "plt.xkcd()\n",
    "plt.figure(figsize= (25, 10))\n",
    "plt.plot(EVR17, color='green', linestyle ='-.', marker='o', markersize=10, markerfacecolor='orange')\n",
    "plt.title('explained variance ratio vs number of principal components', fontsize = 30)\n",
    "plt.xlabel('number of principal components', fontsize = 20)\n",
    "plt.ylabel('explained variance ratio', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "464895ad-38c3-4e9a-a1ad-79351907b2a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*The results suggest that I will get the best test MSE at M=12.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2705701e-de06-413d-9e4f-0ed37cf1a483",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plsfit12 = PLS(n_components=12).fit(scale(X_train), y_train)\n",
    "plspred12 = plsfit12.predict(scale(X_test))\n",
    "plserror12 = mean_squared_error(y_test, plspred12)\n",
    "plserror12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "007f3185-283d-4eac-87f1-1df1fd675cdf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Partial least squares produces significantly lower test MSE than principal components regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbf84d06-74f4-4d93-a1d6-63639714e18c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**g. Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much\n",
    "diference among the test errors resulting from these five approaches?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46a97aa4-0dc6-4927-8e8e-5db6a5a038bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,}'.format\n",
    "error_list = pd.DataFrame([round(lmerror, 2), round(ridgeerror001, 2), round(lassoerror005, 2), round(pcrerror17, 2), round(plserror12, 2)])\n",
    "error_cols = pd.DataFrame(['linear regression', 'ridge regression', 'lasso regression', 'principal components regression', 'partial least squares'])\n",
    "error_df = pd.concat([error_cols, error_list], axis=1)\n",
    "error_df.columns = ['method', 'MSE']\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac82f80-227d-4157-9e9a-4355d84ae39f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plt.figure(figsize = (25, 10))\n",
    "plt.plot(error_df['MSE'], color='green', linestyle ='-.', marker='o', markersize=10, markerfacecolor='orange') # ideally I should be using a histogram, but one of the values is excessively higher than the rest which makes it difficult to view other bars\n",
    "plt.xlabel('method')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE vs method')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Question 9 - answers",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
