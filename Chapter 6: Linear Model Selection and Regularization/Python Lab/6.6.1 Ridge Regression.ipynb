{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdec04ae-2f4e-4b14-a784-d2f3d6b88a5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69ccc2a4-7b09-416a-9634-0fdb7779c4c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da37225e-6538-4119-a674-ae9309d1afb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant statistical packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0d0b49b-f7af-4bb2-b158-3ea88812e150",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant data visualisation packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e99922fa-64d3-4006-b846-ea1e42da6cad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import custom packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from mlxtend.plotting import plot_linear_regression as PLS\n",
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c1df65-bd11-445e-8b26-5f48aa6aa9c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import and preprocess data\n",
    "url = \"abfss://training@sa8451learningdev.dfs.core.windows.net/interpretable_machine_learning/eml_data/Hitters.csv\"\n",
    "Hitters = spark.read.option(\"header\", \"true\").csv(url).toPandas()\n",
    "\n",
    "str_cols = [\"Names\", \"NewLeague\", \"League\", \"Division\"]\n",
    "num_cols = list(set(Hitters.columns) - set(str_cols))\n",
    "Hitters[\"Salary\"] = np.where(Hitters[\"Salary\"] == \"NA\", np.nan, Hitters[\"Salary\"])\n",
    "Hitters[str_cols] = Hitters[str_cols].astype(str)\n",
    "Hitters[num_cols] = Hitters[num_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c34555e1-0ad4-4090-a216-782c4e2e133a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5b2aebd-9264-46a9-aa00-9a9d13958e0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# clean data\n",
    "print(Hitters.shape)\n",
    "Hitters = Hitters.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24827496-3ee0-47f2-a3ed-f7fa734dd4ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16ddf005-484c-403a-9fd2-748dbf871641",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06a544f0-975d-48ef-968b-d8d6312b458b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# converting categorical data into dummy variable\n",
    "Hitters_1 = pd.get_dummies(Hitters, drop_first=True, columns=['League', 'Division', 'NewLeague'])\n",
    "Hitters_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1050fa3-5574-4ac3-bc30-7fa97df229a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e535207-8234-4f57-b4a9-ce995a164cb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17315db3-2581-4af8-b7b8-3c0532001ae7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = Hitters_1.drop(columns = ['Salary', 'Names'])\n",
    "y = Hitters_1.Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2adb8812-cf07-4f4c-9d89-8dcc789276f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# standardisation\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a3a1c4-ea93-4892-a259-94c2f1261995",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "lambdas = (np.logspace(10, -2, num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c21630-8218-4c15-aa90-dab3e242dca4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefs = []\n",
    "MSE = []\n",
    "for k in lambdas:\n",
    "    ridgemod = Ridge(alpha=k, fit_intercept=True, solver='lsqr').fit(X_scaled,y)\n",
    "    coefs.append(ridgemod.coef_)\n",
    "    MSE.append(mean_squared_error(y, ridgemod.predict(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de83285e-eb76-4d37-9bc3-7e4babfc8e37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD = pd.DataFrame(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f781999-331c-4467-aaef-3223e8662913",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d342f3b7-faa8-4707-8811-33d053c1e6b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "897fec7a-4ba8-4d01-8a90-81ac014ea592",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**The book finds the shape of the coefficient matrix to be (100, 20). This actually makes sense because the dataframe above\n",
    "does not contain intercept. So, I will add the intercept at the beginning of each row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20dee7b3-fe67-4f20-b5a4-f12dbaa38be6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ridgemod.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63502eac-aceb-4176-b600-e16dc4349963",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD = pd.concat([pd.DataFrame([ridgemod.intercept_]*100), coefPD], axis=1)\n",
    "coefPD.columns = ['Intercept', 'AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat',\n",
    "       'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists',\n",
    "       'Errors', 'League_N', 'Division_W', 'NewLeague_N']\n",
    "coefPD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67fca87e-41bc-4fb5-a540-4726b2e85a31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lambdas[49] # Python starts counting at 0. This will be equal to ridge.mod$lambda[50] in the book since R starts counting rows at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ef3ce92-c3a9-4912-ae47-b4397db5c26e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.iloc[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d30053-c97f-4d93-905c-8b5cb7463117",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lambdas[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466c7227-e0e2-46a7-8167-e8f65fb75af2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.iloc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3661301a-6726-41b2-aaa3-d86f48eda77e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(25,10))\n",
    "\n",
    "# indexing the five largest coefficients\n",
    "idx = np.argpartition(np.abs(coefs[-1]), -5)[-5:]\n",
    "\n",
    "# standardised coefficients vs lambdas\n",
    "ax1.plot(lambdas, coefs)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('lambda')\n",
    "ax1.set_ylabel('standardized soefficients')\n",
    "ax1.set_title('standardised coefficients vs lambdas')\n",
    "ax1.legend(np.array(ax1.get_lines())[idx], X.columns[idx])\n",
    "\n",
    "# standardised coefficients vs l2 norms\n",
    "l2norm = linalg.norm(coefs[-1])\n",
    "l2coefs = linalg.norm(coefs/l2norm, axis=1)\n",
    "ax2.plot(l2coefs, coefs)\n",
    "ax2.set_xlabel('l2 norm of ridge coefficients / l2 norm of least squares coefficients')\n",
    "ax2.set_ylabel('standardized coefficients')\n",
    "ax2.set_title('standardised coefficients vs l2 norms')\n",
    "ax2.legend(np.array(ax2.get_lines())[idx], X.columns[idx]);\n",
    "\n",
    "# 'Mean Square Error(MSE) vs lambdas\n",
    "ax3.plot(lambdas, MSE)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_xlabel('lambda')\n",
    "ax3.set_ylabel('Mean Square Error(MSE)')\n",
    "ax3.set_title('Mean Square Error(MSE) vs lambdas');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f0bdeb-8224-442f-a05a-3da12a8acc9b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Split dataset into training and test dataset (and standardise them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c6b3497-3711-45cd-9e9b-fe7a94aef0c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = Hitters_1.drop(columns = ['Salary', 'Names'])\n",
    "y = Hitters_1.Salary\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d23ac23-f797-4291-adfb-02a721d26f9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64009bdc-c3f4-4e6d-b255-c3da4b83c6ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MSE with only the intercept\n",
    "lmMSEintercept = np.mean(pow((y_train.mean()-y_test), 2))\n",
    "print(\"MSE with only the intercept: \", lmMSEintercept)\n",
    "\n",
    "# MSE for lambda = 0; this is similar to least squares linear regression\n",
    "lmridge0 = Ridge(alpha=0, fit_intercept=True, solver='lsqr').fit(X_train_scaled, y_train)\n",
    "lmpredict0 = lmridge0.predict(X_test_scaled)\n",
    "lmMSE0 = mean_squared_error(y_test, lmpredict0)\n",
    "print(\"MSE at lambda = 0: \", lmMSE0)\n",
    "\n",
    "# MSE for lambda = 1\n",
    "lmridge1 = Ridge(alpha=1, fit_intercept=True, solver='lsqr').fit(X_train_scaled, y_train)\n",
    "lmpredict1 = lmridge1.predict(X_test_scaled)\n",
    "lmMSE1 = mean_squared_error(y_test, lmpredict1)\n",
    "print(\"MSE at lambda = 1: \", lmMSE1)\n",
    "\n",
    "# MSE for lambda = 4\n",
    "lmridge4 = Ridge(alpha=4, fit_intercept=True, solver='lsqr').fit(X_train_scaled, y_train)\n",
    "lmpredict4 = lmridge4.predict(X_test_scaled)\n",
    "lmMSE4 = mean_squared_error(y_test, lmpredict4)\n",
    "print(\"MSE at lambda = 4: \", lmMSE4)\n",
    "\n",
    "# MSE for lambda = pow(10, 10)\n",
    "lmridge1010 = Ridge(alpha=pow(10, 10), fit_intercept=True, solver='lsqr').fit(X_train_scaled, y_train)\n",
    "lmpredict1010 = lmridge1010.predict(X_test_scaled)\n",
    "lmMSE1010 = mean_squared_error(y_test, lmpredict1010)\n",
    "print(\"MSE at lambda = 10^10: \", lmMSE1010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a0de0b-c604-4a52-afad-f8a2ca90b390",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ridge regression with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98c3097a-9bc2-486b-bfcb-b07937ed90b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# finding the best lambda using CV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "lmridgeCV = RidgeCV(alphas=lambdas, cv=10, scoring='neg_mean_squared_error').fit(X_train_scaled, y_train)\n",
    "lmridgeCValpha = lmridgeCV.alpha_\n",
    "print(\"Best lambda: \", lmridgeCValpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bacc89f-acce-4388-abbd-475950350e8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# performing ridge regression using best lambda\n",
    "lmridge = Ridge(alpha=lmridgeCValpha, fit_intercept=True, solver='lsqr').fit(X_train_scaled, y_train)\n",
    "lmridge_MSE = mean_squared_error(y_test, lmridge.predict(X_test_scaled))\n",
    "print('MSE for best lambda: ', lmridge_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a824479-f91e-4b63-a0e1-7a0917b53836",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "intercept_list = pd.DataFrame([lmridge.intercept_]*19)\n",
    "coef_list = pd.concat([intercept_list, pd.DataFrame([lmridge.coef_]).T], axis = 1)\n",
    "coef_list.reset_index(inplace=True, drop=True)\n",
    "coef_list.columns = ['Intercept', 'Coefficients']\n",
    "coef_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22dd029d-39f9-4e3b-83af-9c1f52412785",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**The main point to note here is that none of the coefficients are zero since ridge regression does not perform variable selection.**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "6.6.1 Ridge Regression",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
