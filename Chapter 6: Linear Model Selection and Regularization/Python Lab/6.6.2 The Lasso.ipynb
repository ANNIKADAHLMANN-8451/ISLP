{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab70adf6-b2ea-4b84-b7c2-a95835c7c90b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d99ff800-eb9d-4e82-9270-8006f2153348",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "710d0a15-c645-4399-b5b8-5d5fb5cfb1b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant statistical packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4ed3910-7794-4a65-b0d9-39442064f4a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant data visualisation packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "273dc155-7bdb-4d32-9738-09ec1b607963",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import custom packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from mlxtend.plotting import plot_linear_regression as PLS\n",
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab8baa7-2481-4bb1-ac09-de84e5355a28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import and preprocess data\n",
    "url = \"abfss://training@sa8451learningdev.dfs.core.windows.net/interpretable_machine_learning/eml_data/Hitters.csv\"\n",
    "Hitters = spark.read.option(\"header\", \"true\").csv(url).toPandas()\n",
    "\n",
    "str_cols = [\"Names\", \"NewLeague\", \"League\", \"Division\"]\n",
    "num_cols = list(set(Hitters.columns) - set(str_cols))\n",
    "Hitters[\"Salary\"] = np.where(Hitters[\"Salary\"] == \"NA\", np.nan, Hitters[\"Salary\"])\n",
    "Hitters[str_cols] = Hitters[str_cols].astype(str)\n",
    "Hitters[num_cols] = Hitters[num_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d98e53d8-7ba2-44a3-b2f4-672ea68fdcec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88eee2e2-218c-463c-993b-cc817515070f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# clean data\n",
    "print(Hitters.shape)\n",
    "Hitters = Hitters.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fc48bb2-b791-4814-89e9-86c9f607566d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb140255-f00f-4cb9-9541-7bfec168175b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47f6799d-c171-42a5-bccf-8087531648ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# converting categorical data into dummy variable\n",
    "Hitters_1 = pd.get_dummies(Hitters, drop_first=True, columns=['League', 'Division', 'NewLeague'])\n",
    "Hitters_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd1f830-e4c0-4fe3-8d8b-ab0687aa7c8c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37ef49d-2989-4d23-82b3-078fb7c7c435",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a19ec99-aec3-48ae-82f7-d785723567d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = Hitters_1.drop(columns = ['Salary', 'Names'])\n",
    "y = Hitters_1.Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d98ea266-e36f-47ff-bbeb-67f07186c03d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# standardisation\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "678ab4a5-9671-452c-b343-f61098f96c01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "lambdas = (np.logspace(10, -2, num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f8f599c-8cf4-48fa-866b-c86a07b1ff63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefs = []\n",
    "MSE = []\n",
    "for k in lambdas:\n",
    "    lassomod = Lasso(alpha=k, fit_intercept=True).fit(X_scaled,y)\n",
    "    coefs.append(lassomod.coef_)\n",
    "    MSE.append(mean_squared_error(y, lassomod.predict(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0947de06-2ae7-438a-9800-53c37a8758b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD = pd.DataFrame(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eca9a42-c203-4311-9cf9-87ca605f7ea2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b49ef4-2568-4932-8fd5-432c2953ef26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dbfcec5-4205-4c47-91f6-a5e07ba1ffa0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**The book finds the shape of the coefficient matrix to be (100, 20). This actually makes sense because the dataframe above\n",
    "does not contain intercept. So, I will add the intercept at the beginning of each row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a05432c-2e8b-42fb-bf57-7c57355de7f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lassomod.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b401e268-99af-4504-9cda-815aa86beae8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD = pd.concat([pd.DataFrame([lassomod.intercept_]*100), coefPD], axis=1)\n",
    "coefPD.columns = ['Intercept', 'AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat',\n",
    "       'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists',\n",
    "       'Errors', 'League_N', 'Division_W', 'NewLeague_N']\n",
    "coefPD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f41abd8-4dcd-431d-9c1f-bbb6f70bdce8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lambdas[49] # Python starts counting at 0. This will be equal to ridge.mod$lambda[50] in the book since R starts counting rows at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a406181e-bfa5-479b-b820-1eb66176a991",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.iloc[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a52882-827c-4a31-b199-150f39803d06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lambdas[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71003a1e-c9b9-4cc2-804a-dd413c6b5d95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefPD.iloc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a93cd08-d7e0-4863-8487-6231feb76194",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(25,10))\n",
    "\n",
    "# indexing the five largest coefficients\n",
    "idx = np.argpartition(np.abs(coefs[-1]), -5)[-5:]\n",
    "\n",
    "# standardized coefficients vs lambdas\n",
    "ax1.plot(lambdas, coefs)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('lambda')\n",
    "ax1.set_ylabel('standardized soefficients')\n",
    "ax1.set_title('standardised coefficients vs lambdas')\n",
    "ax1.legend(np.array(ax1.get_lines())[idx], X.columns[idx])\n",
    "\n",
    "# standardized coefficients vs l2 norms\n",
    "l2norm = linalg.norm(coefs[-1])\n",
    "l2coefs = linalg.norm(coefs/l2norm, axis=1)\n",
    "ax2.plot(l2coefs, coefs)\n",
    "ax2.set_xlabel('l2 norm of ridge coefficients / l2 norm of least squares coefficients')\n",
    "ax2.set_ylabel('standardized coefficients')\n",
    "ax2.set_title('standardised coefficients vs l2 norms')\n",
    "ax2.legend(np.array(ax2.get_lines())[idx], X.columns[idx]);\n",
    "\n",
    "# 'Mean Square Error(MSE) vs lambdas\n",
    "ax3.plot(lambdas, MSE)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_xlabel('lambda')\n",
    "ax3.set_ylabel('Mean Square Error(MSE)')\n",
    "ax3.set_title('Mean Square Error(MSE) vs lambdas');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ddd064-1194-492f-8578-4bc453b446eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**It is quite interesting to note how different variables reach 0 at different intervals. This is better visualised in the\n",
    "middle plot where different predictors enter the model one by one at different intervals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f734e3-2381-4068-a43b-64e01e8cd0ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Split dataset into training and test dataset (and standardise them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38cbf3c-b912-4514-babb-4a05c1befcb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = Hitters_1.drop(columns = ['Salary', 'Names'])\n",
    "y = Hitters_1.Salary\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e448827-3d0d-4f61-8d41-af575524fcaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# standardisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48fdb899-6501-494c-9980-d1f7afa59025",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MSE with only the intercept\n",
    "lmMSEintercept = np.mean(pow((y_train.mean()-y_test), 2))\n",
    "print(\"MSE with only the intercept: \", lmMSEintercept)\n",
    "\n",
    "# MSE for lambda = 0; this is similar to least squares linear regression\n",
    "lmlasso0 = Lasso(alpha=0, fit_intercept=True).fit(X_train_scaled, y_train)\n",
    "lmpredict0 = lmlasso0.predict(X_test_scaled)\n",
    "lmMSE0 = mean_squared_error(y_test, lmpredict0)\n",
    "print(\"MSE at lambda = 0: \", lmMSE0)\n",
    "\n",
    "# MSE for lambda = 1\n",
    "lmridge1 = Lasso(alpha=1, fit_intercept=True).fit(X_train_scaled, y_train)\n",
    "lmpredict1 = lmridge1.predict(X_test_scaled)\n",
    "lmMSE1 = mean_squared_error(y_test, lmpredict1)\n",
    "print(\"MSE at lambda = 1: \", lmMSE1)\n",
    "\n",
    "# MSE for lambda = 4\n",
    "lmlasso4 = Lasso(alpha=4, fit_intercept=True).fit(X_train_scaled, y_train)\n",
    "lmpredict4 = lmlasso4.predict(X_test_scaled)\n",
    "lmMSE4 = mean_squared_error(y_test, lmpredict4)\n",
    "print(\"MSE at lambda = 4: \", lmMSE4)\n",
    "\n",
    "# MSE for lambda = pow(10, 10)\n",
    "lmlasso1010 = Lasso(alpha=pow(10, 10), fit_intercept=True).fit(X_train_scaled, y_train)\n",
    "lmpredict1010 = lmlasso1010.predict(X_test_scaled)\n",
    "lmMSE1010 = mean_squared_error(y_test, lmpredict1010)\n",
    "print(\"MSE at lambda = 10^10: \", lmMSE1010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53e76a87-7472-4e7c-b36f-a887590c6035",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Lasso regression with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5e10695-7acb-4d49-bd34-183df69de6e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# finding the best lambda using CV\n",
    "from sklearn.linear_model import LassoCV\n",
    "lmlassoCV = LassoCV(alphas=lambdas, cv=10).fit(X_train_scaled, y_train)\n",
    "lmlassoCValpha = lmlassoCV.alpha_\n",
    "print(\"Best lambda: \", lmlassoCValpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9de4a35-01a1-4eb0-bdc9-f6e9d56a7590",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# performing lasso regression using best lambda\n",
    "lmlasso = Lasso(alpha=lmlassoCValpha, fit_intercept=True).fit(X_train_scaled, y_train)\n",
    "lmlasso_MSE = mean_squared_error(y_test, lmlasso.predict(X_test_scaled))\n",
    "print('MSE for best lambda: ', lmlasso_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c393fd-2609-4ac1-8be3-94e2e6a8bbdc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "intercept_list = pd.DataFrame([lmlasso.intercept_]*19)\n",
    "coef_list = pd.concat([intercept_list, pd.DataFrame([lmlasso.coef_]).T], axis = 1)\n",
    "coef_list.reset_index(inplace=True, drop=True)\n",
    "coef_list.columns = ['Intercept', 'Coefficients']\n",
    "coef_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4b5e3c1-eeb6-4eb9-bdba-30af018903bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Two points of note:**<br>\n",
    "**1. The test errors of lasso regression are comparable to those of ridge regression.**\n",
    "<br>\n",
    "**2. 9 out of 18 coefficients are exactly 0. This suggests that lasso regression can perform feature selection as well as variance reduction.**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "6.6.2 The Lasso",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
