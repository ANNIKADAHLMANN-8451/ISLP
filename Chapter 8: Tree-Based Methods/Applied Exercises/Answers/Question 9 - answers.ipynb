{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e68c31ca-3b9b-4165-8ce3-7360737e4671",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This problem involves the `OJ` data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420dcff1-063a-4b63-b0c5-53cc82c4dfcc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c303ea-5e64-406a-b143-d0abef772d4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant statistical packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51eeaa08-1d6d-4124-8bef-cacabad8eaaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import data visualisation packages\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d884a3b2-1d8d-44d0-b74c-b8cb9a48e287",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "url = \"abfss://training@sa8451learningdev.dfs.core.windows.net/interpretable_machine_learning/eml_data/OJ.csv\"\n",
    "df = spark.read.option(\"header\", \"true\").csv(url).toPandas()\n",
    "df.set_index(\"SlNo\", inplace=True)\n",
    "\n",
    "str_cols = [\"Purchase\", \"Store7\"]\n",
    "float_cols = [\"PriceCH\", \"PriceMM\", \"DiscCH\", \"DiscMM\", \"LoyalCH\", \"SalePriceMM\", \"SalePriceCH\", \"PriceDiff\", \"PctDiscMM\", \"PctDiscCH\", \"ListPriceDiff\"]\n",
    "int_cols = list(set(df.columns)-set(str_cols)-set(float_cols))\n",
    "df[str_cols] = df[str_cols].astype(str)\n",
    "df[float_cols] = df[float_cols].astype(float)\n",
    "df[int_cols] = df[int_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fab15277-d148-40ad-a19e-16cd04269d71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "517e59d7-46ed-435b-972c-73dae4bad2db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.Purchase = df.Purchase.map(lambda x: 1 if x=='CH' else 0)\n",
    "df.Store7 = df.Store7.map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b047a5d2-e4e6-4667-a4e6-37f4ae9debb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8c7352-cdc8-489f-aaae-46324f9302ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c127a096-c704-4a59-a53e-3bde7f0f7630",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**a. Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83955020-17cb-4f65-b53d-778abdcfa739",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='Purchase') # For this, I checked question 9.b. to find out the response variable\n",
    "y = df.Purchase\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.747663551402, test_size=0.25233644859, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddec70f9-df6e-48ba-97a4-af688240da2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7987f886-ba2e-4939-a493-03d20bebbdd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**b. Fit a tree to the training data, with `Purchase` as the response\n",
    "and the other variables as predictors. What is the training error\n",
    "rate?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8df0be-244a-414a-94af-48fe5fae1bc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 6).fit(X_train, y_train)\n",
    "tree_score = tree.score(X_train, y_train)\n",
    "print(\"Training error rate: \", round(1-tree_score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60bbd586-8a07-4821-a4ef-db44502a5a60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fa2c3ce-0dd6-43d8-8a6c-3993f2327e8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tree_pred = tree.predict(X_test)\n",
    "class_mat = pd.DataFrame(confusion_matrix(y_test, tree_pred).T, index = ['No', 'Yes'], columns = ['No', 'Yes'])\n",
    "print(class_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed90b067-b3c3-44be-823a-0105a3b12197",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97a4886b-d5bf-4372-9b2e-68e4aa8a0261",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9da7033d-c7ff-477f-a611-eb92a97f3b07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The training error is approximately 0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40fcd547-8533-467d-bd57-702d90809243",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**c. How many\n",
    "terminal nodes does the tree have?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3a404e-27c0-40e4-8779-faa2a16d9dbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "42 leave nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7c43488-76d5-4b9d-9498-b233b20cf30e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**f. Use cross-validation on the training set in order to determine\n",
    "the optimal tree size.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "356dc58c-0884-4428-9f1b-2d0f30bc0ce8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SCORES = []\n",
    "max_leafs_arr = range(2, 50)\n",
    "for max_leafs in max_leafs_arr:\n",
    "    regressionTree = DecisionTreeClassifier(max_leaf_nodes=max_leafs)\n",
    "    sc = cross_val_score(regressionTree, X, y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "    SCORES.append((-sc.mean(), sc.std()))\n",
    "SCORES = np.array(SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e472fd7b-d40b-4f8d-aedb-14ecd5b6e491",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(max_leafs_arr, SCORES[:,0], 'g')\n",
    "plt.fill_between(max_leafs_arr, SCORES[:,0]+SCORES[:,1], SCORES[:,0]-SCORES[:,1], alpha=0.3, color='y')\n",
    "plt.xlabel('tree size', fontsize=20, color='c')\n",
    "plt.ylabel('MSE', fontsize=20, color='c')\n",
    "plt.title('finding the best tree through cross-validation', fontsize=30, color='m')\n",
    "best_min_leafs = max_leafs_arr[np.argmin(SCORES[:,0])]\n",
    "print(f\"The best tree has {best_min_leafs} leafs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec427f11-fcc0-46f5-8d35-781256f483d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Therefore, a tree at $m$=10 leaves has the lowest cross-validated classification error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba257ba2-e225-42cb-9958-6fefc432a0c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**i. Produce a pruned tree corresponding to the optimal tree size\n",
    "obtained using cross-validation. If cross-validation does not lead\n",
    "to selection of a pruned tree, then create a pruned tree with fve\n",
    "terminal nodes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85324094-0574-478f-b155-0d88b4dc0c9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruned_tree = DecisionTreeClassifier(max_depth = 10)\n",
    "pruned_tree.fit(X_train, y_train)\n",
    "pruned_tree_score = pruned_tree.score(X_train, y_train)\n",
    "print(\"Training error rate: \", round(1-pruned_tree_score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dbd3cff-84b4-4907-8dce-287665120276",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Therefore, non-pruned tree results in higher training error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1843c923-a44c-4c22-ac1c-6dce983ca9eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruned_tree_pred = pruned_tree.predict(X_test)\n",
    "pruned_class_mat = pd.DataFrame(confusion_matrix(y_test, pruned_tree_pred).T, index = ['No', 'Yes'], columns = ['No', 'Yes'])\n",
    "print(pruned_class_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c695ef5-6b52-4eb9-879e-8d707bb3b91a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pruned_tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86aa73b2-b371-477b-a5d2-1ae7ab51fd9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Therefore, pruned tree results in higher test error rate."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Question 9 - answers",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
